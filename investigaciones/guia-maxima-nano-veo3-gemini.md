# Gu√≠a Profunda: Maximizar Nano Banana y Veo 3 con Gemini Pro

## üéØ Tabla de Contenidos
1. [Mejores Pr√°cticas de Prompting](#prompting)
2. [Optimizaciones de API y CLI](#optimizaciones)
3. [Extensiones y Herramientas](#extensiones)
4. [Scripts Listos para Producci√≥n](#scripts)
5. [Hacks y Trucos Avanzados](#hacks)

---

## <a name="prompting"></a>1. Mejores Pr√°cticas de Prompting

### 1.1 Estructura Modular de Prompts (Nano Banana - Im√°genes)

#### El Blueprint Comprobado (Skywork 2025):

```
[SUBJECT]: Tu sujeto principal y atributos clave.

[COMPOSITION]: Encuadre, fondo, profundidad de campo, intenci√≥n de aspecto.

[LIGHTING/CAMERA]: Calidad de luz, notas de lente/c√°mara, hora del d√≠a.

[STYLE/REFERENCES]: Adjetivos de estilo, referencias, materiales/paleta.

[CONSTRAINTS/EXCLUSIONS]: Sin superposici√≥n de texto, sin marcas de agua, sin dedos extra, evitar desorden.

[EDIT SEQUENCE]: Si editas, especifica paso 1 solamente; guarda otros para el siguiente turno.
```

#### Ejemplo Real (Para Fotograf√≠a de Producto):

```
[SUBJECT]: Reloj de lujo suizo, correa de cuero marr√≥n, esfera blanca con n√∫meros romanos.

[COMPOSITION]: Plano medio, fondo blanco limpio, perspectiva diagonal 45¬∞, fondo desenfocado.

[LIGHTING/CAMERA]: Luz de estudio frontal suave, sombras dram√°ticas sutiles, lente macro f/2.8, 200mm.

[STYLE/REFERENCES]: Fotograf√≠a comercial profesional, cat√°logo de lujo, colores naturales.

[CONSTRAINTS/EXCLUSIONS]: Sin reflejos fuertes, sin texto, enfoque n√≠tido en la cara del reloj.

[EDIT SEQUENCE]: Ajustar brillo +10%, reducir saturaci√≥n roja -15%.
```

**¬øPor qu√© funciona?** Google admite lenguaje natural sin restricciones, pero separar cl√°usulas elimina ambig√ºedad. La comunidad de 2025 converge en prompts multi-cl√°usula y negativos sem√°nticos.

### 1.2 T√©cnicas por Tipo de Contenido

#### Escenas Fotorrealistas
- **Keywords clave**: "high detail", "8K resolution", "natural colors"
- **Detalles a incluir**: Clima, objetos de fondo, √°ngulos espec√≠ficos de c√°mara
- **Truco**: Menciona el tipo de c√°mara: "Shot on Hasselblad X2D, 100MP"

#### Ilustraciones Estilizadas
- **Keywords**: "cartoon style", "flat vector", "sticker design"
- **Simplifica**: Menos detalles = imagen m√°s limpia
- **Paleta**: Especifica colores: "bold primary colors, minimal shadows"

#### Texto en Im√°genes (El Gran Desaf√≠o)
- **S√© extremadamente espec√≠fico**: "sans-serif bold, all caps, white text on dark background"
- **Incluye contexto**: "on a coffee shop menu board, hand-written style"
- **Truco**: Describe posici√≥n: "text centered at top, 3 lines, 40pt font"

#### Maquetas de Producto
- **√ânfasis**: "studio shot", "white background", "commercial mockup"
- **Especifica**: Material, tama√±o, contexto (ej: "matte black earbuds on marble surface")

### 1.3 Negaciones Sem√°nticas (No "No...")

‚ùå **MALO**: "no people, no watermark, no blurry"

‚úÖ **BUENO**: "empty scene with clean architecture, professional studio lighting, crystal clear focus throughout"

**Raz√≥n**: Nano Banana entiende mejor instrucciones positivas. En lugar de prohibir, describe lo que S√ç quieres.

---

## <a name="prompting-veo"></a>1.4 Prompting Avanzado para Veo 3 (Videos)

### F√≥rmula Probada (100+ generaciones):

```
[SHOT TYPE] + [SUBJECT] [ACTION] [STYLE] + [DIRECTOR/ERA] + [AUDIO CUES]
```

#### Ejemplo Profesional:

```
Medium shot de un hacker cyberpunk digitando fren√©ticamente, con reflejos ne√≥n iluminando su cara, 
en est√©tica Blade Runner, con lente cinematogr√°fica de 50mm. Sonido: clics de teclado mec√°nico y sirenas distantes.
```

### Reglas de Oro para Veo 3:

1. **Front-load lo importante**: Veo 3 pondera m√°s las primeras palabras
2. **Define el "QU√â" antes del "C√ìMO"**: Primero el objeto, luego los detalles visuales
3. **Una acci√≥n por prompt**: Multiple acciones = confusi√≥n
4. **S√© espec√≠fico sobre emociones**: "shuffling with hunched shoulders" > "walking sadly"
5. **No olvides audio**: La mayor√≠a ignora esto; es un error cr√≠tico

### Movimientos de C√°mara que Funcionan:

- ‚úÖ Slow push/pull (dolly in/out)
- ‚úÖ Orbiting alrededor del sujeto
- ‚úÖ Handheld following (natural)
- ‚úÖ Static shots con movimiento de sujeto

- ‚ùå Combinaciones complejas (pan + zoom + dolly simult√°neamente)
- ‚ùå Movimientos sin motivaci√≥n
- ‚ùå M√∫ltiples puntos focales

### Referencias de Estilo que Funcionan:

```
"Shot on RED Helium 8K"
"Spielberg cinematography, dramatic lighting"
"Mad Max Fury Road color grading, desaturated with orange/teal"
```

---

## <a name="optimizaciones"></a>2. Optimizaciones de API y CLI

### 2.1 Context Caching (La Arma Secreta)

**Beneficio**: Reduce costo de tokens en ~4x comparado a m√©todos tradicionales.

```python
from google import genai

client = genai.Client(api_key="TU_API_KEY")

# Definir context a cachear (ej: system instructions largo)
system_instructions = """
Eres un experto en generaci√≥n de prompts para Nano Banana...
[Aqu√≠ va contenido largo que se reutilizar√°...]
""" * 10  # Repetir para alcanzar m√≠nimo 4096 tokens

# Primera llamada: se cachea el contexto
response1 = client.models.generate_content(
    model="gemini-2.5-flash",
    contents=[
        {
            "parts": [{"text": system_instructions}],
            "role": "user"
        },
        {
            "parts": [{"text": "Genera un prompt para fotograf√≠a de producto"}],
            "role": "user"
        }
    ],
    system_instruction="cacheable_system_prompt"
)

# Llamadas posteriores: reutiliza contexto cacheado (4x m√°s barato)
response2 = client.models.generate_content(
    model="gemini-2.5-flash",
    contents=[
        {
            "parts": [{"text": "Genera un prompt para paisaje"}],
            "role": "user"
        }
    ]
)
```

**Costos (Gemini Flash)**:
- Tokens normales: $0.075 por mill√≥n
- Tokens cacheados: $0.02 por mill√≥n (¬°75% descuento!)
- Almacenamiento: $1.00 por mill√≥n tokens/hora

**TTL recomendado**: 3600 segundos (1 hora) para uso interactivo.

### 2.2 Batch API (50% de descuento)

Perfecto para generar 100+ im√°genes sin presi√≥n de tiempo.

```python
from google import genai
import time

client = genai.Client(api_key="TU_API_KEY")

# Preparar N solicitudes
prompts = [
    "Un drag√≥n rojo volando sobre monta√±as nevadas",
    "Una ciudad cyberpunk bajo lluvia √°cida",
    "Bosque antiguo con criaturas m√°gicas",
    # ... m√°s prompts
]

inline_requests = [
    {
        "contents": [{"parts": [{"text": prompt}], "role": "user"}]
    }
    for prompt in prompts
]

# Crear trabajo batch
batch_job = client.batches.create(
    model="gemini-2.5-flash",
    src=inline_requests,
    config={"display_name": "image-generation-batch-001"}
)

print(f"Batch creado: {batch_job.name}")

# Esperar a que se complete
while True:
    batch_status = client.batches.get(name=batch_job.name)
    if batch_status.state.name in ('JOB_STATE_SUCCEEDED', 'JOB_STATE_FAILED'):
        break
    print(f"Estado: {batch_status.state.name}. Esperando...")
    time.sleep(30)

# Procesar resultados
if batch_status.state.name == 'JOB_STATE_SUCCEEDED':
    for i, response in enumerate(batch_status.dest.inlined_responses):
        print(f"Respuesta {i}: {response.response.text}")
```

**Ventajas**:
- 50% de descuento vs. llamadas individuales
- Ideal para workflows as√≠ncronos
- No hay l√≠mites de tasa mientras se procesa

### 2.3 Token Counting y Optimizaci√≥n

```python
from google import genai

client = genai.Client(api_key="TU_API_KEY")
model = "gemini-2.5-flash"

def estimate_tokens(prompt, system_instruction=""):
    """Estima tokens sin hacer llamada costosa"""
    response = client.models.count_tokens(
        model=model,
        contents={"parts": [{"text": prompt}]},
        system_instruction=system_instruction
    )
    return response.total_tokens

# Ejemplo
prompt = "Genera un prompt detallado para Nano Banana de una fotograf√≠a de paisaje..."
token_count = estimate_tokens(prompt)
print(f"Tokens estimados: {token_count}")

# Optimizaci√≥n: si > 4000 tokens, considera batching
if token_count > 4000:
    print("‚ö†Ô∏è Considera usar Batch API para esta solicitud")
```

### 2.4 Rate Limits √ìptimos

**Free Tier**: 5-15 solicitudes/minuto
**Flash Model**: 2000 solicitudes/minuto (paid)
**Pro Model**: 1000 solicitudes/minuto (paid)

**Estrategia**:
```python
import time
from functools import wraps

def rate_limit(calls_per_minute=10):
    min_interval = 60.0 / calls_per_minute
    last_called = [0.0]
    
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            elapsed = time.time() - last_called[0]
            wait_time = min_interval - elapsed
            if wait_time > 0:
                time.sleep(wait_time)
            result = func(*args, **kwargs)
            last_called[0] = time.time()
            return result
        return wrapper
    return decorator

@rate_limit(calls_per_minute=5)  # Conservative para free tier
def generate_with_nanba_banana(prompt):
    client = genai.Client(api_key="TU_API_KEY")
    return client.models.generate_content(
        model="gemini-2.5-flash-image-preview",
        contents=[{"parts": [{"text": prompt}]}]
    )
```

---

## <a name="extensiones"></a>3. Extensiones y Herramientas CLI

### 3.1 Gemini CLI Extensions (Nuevo en Oct 2025)

Instalaci√≥n b√°sica:

```bash
# Instalar Gemini CLI
npm install -g gemini-cli

# Instalar extensi√≥n para Nano Banana
gemini extensions install https://github.com/google-gemini/nanobanana-extension

# Usar desde CLI
gemini "Genera una imagen de un drag√≥n"
```

#### Crear Tu Propia Extensi√≥n:

```yaml
# extension.yaml
name: "my-image-generator"
version: "1.0.0"

mcpServers:
  nanobanana:
    command: npx
    args: ["@google-gemini/nanobanana-mcp"]

customCommands:
  /img:
    description: "Generar imagen con estructura modular"
    prompt: |
      Usa esta estructura:
      [SUBJECT]: {arg1}
      [COMPOSITION]: {arg2}
      [LIGHTING/CAMERA]: {arg3}
      [STYLE/REFERENCES]: {arg4}
      
contextFiles:
  - GEMINI.md

excludedTools:
  - web_search
```

### 3.2 Pollinations.AI CLI Automation

```bash
# Instalaci√≥n simple
pip install requests

# Script batch
cat > batch_images.py << 'EOF'
import requests
from concurrent.futures import ThreadPoolExecutor
import time

prompts = [
    "un drag√≥n rojo",
    "ciudad cyberpunk",
    "bosque m√°gico",
]

def generate_image(prompt, index):
    url = f"https://pollinations.ai/p/{prompt.replace(' ', '_')}"
    response = requests.get(url, timeout=30)
    
    if response.status_code == 200:
        with open(f"image_{index}.jpg", "wb") as f:
            f.write(response.content)
        print(f"‚úì Guardada: image_{index}.jpg")
    else:
        print(f"‚úó Error para: {prompt}")

# Ejecutar en paralelo (m√°ximo 3 simult√°neamente)
with ThreadPoolExecutor(max_workers=3) as executor:
    for i, prompt in enumerate(prompts):
        executor.submit(generate_image, prompt, i)

EOF

python batch_images.py
```

### 3.3 n8n Workflow para Automatizaci√≥n Completa

Crea un workflow que:
1. Recibe prompts desde Telegram
2. Genera im√°genes con Pollinations
3. Las guarda en Google Drive
4. Registra en Google Sheets

```yaml
# Nodos principales:
- Telegram Input Trigger
- Create Pollinations Image URL
- Download Image
- Upload to Google Drive
- Log to Google Sheets
- Send Result to User
```

Obt√©n workflow listo en: `n8n.io/workflows/5844`

---

## <a name="scripts"></a>4. Scripts Listos para Producci√≥n

### 4.1 Generador Batch Completo (Nano Banana)

```python
#!/usr/bin/env python3
"""
Script para generar m√∫ltiples im√°genes con Nano Banana usando Batch API
Uso: python batch_generator.py --config config.json
"""

import argparse
import json
import time
from google import genai
from pathlib import Path

def load_config(config_path):
    with open(config_path, 'r') as f:
        return json.load(f)

def create_batch_requests(prompts, config):
    """Crear solicitudes batch con estructura modular"""
    requests = []
    
    for i, prompt_data in enumerate(prompts):
        if isinstance(prompt_data, str):
            text = prompt_data
        else:
            # Formato estructurado
            text = f"""
[SUBJECT]: {prompt_data.get('subject', '')}
[COMPOSITION]: {prompt_data.get('composition', '')}
[LIGHTING/CAMERA]: {prompt_data.get('lighting', '')}
[STYLE/REFERENCES]: {prompt_data.get('style', '')}
[CONSTRAINTS/EXCLUSIONS]: {prompt_data.get('constraints', '')}
""".strip()
        
        requests.append({
            "contents": [{"parts": [{"text": text}], "role": "user"}],
            "metadata": {"key": f"prompt_{i}"}
        })
    
    return requests

def submit_batch(client, requests, config):
    """Enviar batch a API"""
    batch_job = client.batches.create(
        model=config.get("model", "gemini-2.5-flash"),
        src=requests,
        config={"display_name": config.get("batch_name", "batch_images")}
    )
    return batch_job

def poll_batch_status(client, batch_name, poll_interval=30, max_wait=3600):
    """Esperar a que se complete el batch"""
    start_time = time.time()
    
    while True:
        batch = client.batches.get(name=batch_name)
        
        print(f"[{time.strftime('%H:%M:%S')}] Estado: {batch.state.name}")
        
        if batch.state.name in ('JOB_STATE_SUCCEEDED', 'JOB_STATE_FAILED'):
            return batch
        
        elapsed = time.time() - start_time
        if elapsed > max_wait:
            raise TimeoutError(f"Batch excedi√≥ {max_wait} segundos")
        
        time.sleep(poll_interval)

def save_results(batch, output_dir):
    """Guardar resultados en archivos"""
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)
    
    results = []
    for i, response in enumerate(batch.dest.inlined_responses):
        if response.response:
            text = response.response.text
            results.append({
                "id": i,
                "prompt_key": response.metadata.get("key", "unknown"),
                "output": text
            })
            
            # Guardar en archivo individual
            with open(output_dir / f"result_{i}.txt", "w") as f:
                f.write(text)
    
    # Guardar resumen JSON
    with open(output_dir / "summary.json", "w") as f:
        json.dump(results, f, indent=2)
    
    return results

def main():
    parser = argparse.ArgumentParser(description="Batch Image Generator con Nano Banana")
    parser.add_argument("--config", required=True, help="Ruta al archivo de configuraci√≥n JSON")
    parser.add_argument("--output", default="./output", help="Directorio de salida")
    args = parser.parse_args()
    
    # Cargar configuraci√≥n
    config = load_config(args.config)
    prompts = config.get("prompts", [])
    
    # Inicializar cliente
    client = genai.Client(api_key=config.get("api_key"))
    
    print(f"üìù Preparando {len(prompts)} prompts...")
    requests = create_batch_requests(prompts, config)
    
    print("üöÄ Enviando batch a API...")
    batch = submit_batch(client, requests, config)
    print(f"‚úì Batch creado: {batch.name}")
    
    print("‚è≥ Esperando resultados...")
    completed_batch = poll_batch_status(client, batch.name)
    
    if completed_batch.state.name == 'JOB_STATE_SUCCEEDED':
        print("‚úÖ Batch completado exitosamente")
        results = save_results(completed_batch, args.output)
        print(f"‚úì Resultados guardados en: {args.output}")
        print(f"‚úì Total de resultados: {len(results)}")
    else:
        print(f"‚ùå Batch fall√≥: {completed_batch.state.name}")

if __name__ == "__main__":
    main()
```

**Archivo config.json**:

```json
{
  "api_key": "TU_API_KEY_AQUI",
  "model": "gemini-2.5-flash",
  "batch_name": "creative_batch_001",
  "prompts": [
    {
      "subject": "Reloj de lujo suizo",
      "composition": "Plano medio, fondo blanco",
      "lighting": "Estudio profesional, luz frontal suave",
      "style": "Fotograf√≠a comercial, 8K",
      "constraints": "Sin texto, n√≠tido, enfoque en esfera"
    },
    {
      "subject": "Dragon rojo √©pico",
      "composition": "Plano a√©reo, volando sobre monta√±as",
      "lighting": "Atardecer, cielo dorado",
      "style": "Fantas√≠a √©pica, fotorrealista",
      "constraints": "Detalles de escamas n√≠tidas"
    }
  ]
}
```

### 4.2 Veo 3 Image-to-Video Script

```python
#!/usr/bin/env python3
"""
Convertir im√°genes a videos con Veo 3
Prerequisito: pip install google-generativeai google-cloud-storage
"""

import os
import time
from pathlib import Path
from google import genai
import mimetypes

def upload_image(client, image_path):
    """Subir imagen a File API"""
    mime_type, _ = mimetypes.guess_type(image_path)
    
    with open(image_path, "rb") as f:
        uploaded_file = client.files.upload(
            file=f,
            mime_type=mime_type
        )
    
    print(f"‚úì Imagen subida: {uploaded_file.name}")
    return uploaded_file

def generate_video_from_image(client, image_file, prompt, output_path="output.mp4"):
    """Generar video desde imagen usando Veo 3"""
    
    operation = client.models.generate_videos(
        model="veo-3.1-generate-preview",
        contents=[image_file],
        prompt=prompt,
        config={
            "aspect_ratio": "16:9",
            "negative_prompt": "cartoon, low quality, blurry",
            "duration_seconds": 10
        }
    )
    
    print("‚è≥ Generando video... (esto puede tomar 1-5 minutos)")
    
    # Esperar a que se complete
    while not operation.done:
        print(f"  Estado: {operation.metadata.get('state', 'procesando')}...")
        time.sleep(10)
        operation = client.operations.get(operation.name)
    
    if operation.response:
        video_content = operation.response.generated_videos[0]
        
        # Descargar video
        with open(output_path, "wb") as f:
            f.write(video_content.video)
        
        print(f"‚úì Video guardado: {output_path}")
        return output_path
    else:
        print("‚ùå Error generando video")
        return None

def batch_image_to_video(image_dir, prompt_template, output_dir="./videos"):
    """Convertir m√∫ltiples im√°genes a videos"""
    client = genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))
    Path(output_dir).mkdir(exist_ok=True)
    
    images = list(Path(image_dir).glob("*.{jpg,png,jpeg}"))
    print(f"üìÅ Encontradas {len(images)} im√°genes")
    
    for i, image_path in enumerate(images, 1):
        print(f"\n[{i}/{len(images)}] Procesando: {image_path.name}")
        
        # Subir imagen
        uploaded = upload_image(client, str(image_path))
        
        # Generar prompt personalizado
        prompt = prompt_template.format(image_name=image_path.stem)
        
        # Generar video
        output_file = f"{output_dir}/{image_path.stem}_video.mp4"
        generate_video_from_image(client, uploaded, prompt, output_file)
        
        # Limpiar (opcional: eliminar archivo despu√©s de procesarlo)
        # client.files.delete(name=uploaded.name)

if __name__ == "__main__":
    # Ejemplo de uso
    image_dir = "./images"
    output_dir = "./videos"
    
    prompt_template = "Anima {image_name} con movimiento cinematogr√°fico suave, 4K quality"
    
    batch_image_to_video(image_dir, prompt_template, output_dir)
```

### 4.3 ComfyUI API Automation (Generaci√≥n Local)

```python
#!/usr/bin/env python3
"""
Automatizar ComfyUI localmente con HTTP API
Primero: iniciar ComfyUI con --listen 0.0.0.0 --port 8188
"""

import requests
import json
import urllib.request
import urllib.parse
import time
from pathlib import Path

COMFY_SERVER = "http://127.0.0.1:8188"

def get_models(server=COMFY_SERVER):
    """Listar modelos disponibles"""
    response = requests.get(f"{server}/api/models")
    return response.json()

def create_workflow_json(prompt, model_name, steps=20):
    """Crear workflow JSON para Flux/SDXL"""
    workflow = {
        "1": {
            "class_type": "CheckpointLoader",
            "inputs": {"ckpt_name": model_name}
        },
        "2": {
            "class_type": "CLIPTextEncode",
            "inputs": {"text": prompt, "clip": ["1", 1]}
        },
        "3": {
            "class_type": "KSampler",
            "inputs": {
                "seed": 12345,
                "steps": steps,
                "cfg": 7.5,
                "sampler_name": "euler",
                "scheduler": "normal",
                "denoise": 1.0,
                "model": ["1", 0],
                "positive": ["2", 0],
                "latent_image": ["5", 0]
            }
        },
        "4": {
            "class_type": "VAEDecode",
            "inputs": {"samples": ["3", 0], "vae": ["1", 2]}
        },
        "5": {
            "class_type": "EmptyLatentImage",
            "inputs": {"width": 1024, "height": 1024, "batch_size": 1}
        },
        "6": {
            "class_type": "SaveImage",
            "inputs": {"images": ["4", 0], "filename_prefix": "generated"}
        }
    }
    return workflow

def queue_prompt(workflow, server=COMFY_SERVER):
    """Enviar workflow a cola"""
    p = {"prompt": workflow}
    data = json.dumps(p).encode('utf-8')
    req = urllib.request.Request(
        f"{server}/prompt",
        data=data
    )
    
    with urllib.request.urlopen(req) as response:
        return json.loads(response.read())

def get_history(prompt_id, server=COMFY_SERVER):
    """Obtener historia de ejecuci√≥n"""
    with urllib.request.urlopen(f"{server}/history/{prompt_id}") as response:
        return json.loads(response.read())

def batch_generate(prompts, model="flux-dev", output_dir="./outputs"):
    """Generar m√∫ltiples im√°genes"""
    Path(output_dir).mkdir(exist_ok=True)
    
    print(f"üé® Generando {len(prompts)} im√°genes con {model}...")
    
    for i, prompt in enumerate(prompts, 1):
        print(f"\n[{i}/{len(prompts)}] {prompt[:50]}...")
        
        # Crear workflow
        workflow = create_workflow_json(prompt, model)
        
        # Encolar
        result = queue_prompt(workflow)
        prompt_id = result.get("prompt_id")
        
        print(f"  ID de promedio: {prompt_id}")
        
        # Esperar (timeout 5 minutos)
        start = time.time()
        while time.time() - start < 300:
            try:
                history = get_history(prompt_id)
                if prompt_id in history:
                    print(f"  ‚úì Generada exitosamente")
                    break
            except:
                pass
            time.sleep(2)

if __name__ == "__main__":
    prompts = [
        "Un drag√≥n rojo volando sobre ciudades futuristas",
        "Bosque encantado bajo la luz de la luna, estilo anime",
        "Retrato de una mujer cyberpunk, color neon",
    ]
    
    batch_generate(prompts, model="flux-schnell")
```

---

## <a name="hacks"></a>5. Hacks y Trucos Avanzados

### 5.1 Multi-Model Chaining (Nano Banana ‚Üí Veo 3 ‚Üí Upscale)

```python
#!/usr/bin/env python3
"""
Pipeline completo:
1. Generar imagen con Nano Banana
2. Animar con Veo 3
3. Upscalar
"""

from google import genai
import time
import os

client = genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))

def step1_generate_image(prompt):
    """Paso 1: Generar imagen base"""
    print("üì∏ Generando imagen con Nano Banana...")
    
    response = client.models.generate_content(
        model="gemini-2.5-flash-image-preview",
        contents=[{"parts": [{"text": prompt}]}]
    )
    
    # Extraer imagen (nota: la respuesta aqu√≠ es conceptual)
    image_data = response.candidates[0].content.parts[0].inline_data.data
    return image_data

def step2_animate_image(image_data, motion_prompt):
    """Paso 2: Animar imagen con Veo 3"""
    print("üé¨ Animando con Veo 3...")
    
    operation = client.models.generate_videos(
        model="veo-3.1-generate-preview",
        contents=[image_data],
        prompt=motion_prompt,
        config={"aspect_ratio": "16:9"}
    )
    
    # Esperar
    while not operation.done:
        time.sleep(5)
        operation = client.operations.get(operation.name)
    
    return operation.response.generated_videos[0]

def step3_upscale_video(video_data):
    """Paso 3: Upscalar video (usando Vertex AI si est√° disponible)"""
    print("‚¨ÜÔ∏è Upscalando video...")
    
    # Aqu√≠ ir√≠a el c√≥digo de upscaling
    # Por ahora es conceptual
    return video_data

# Uso:
image = step1_generate_image(
    "[SUBJECT]: Drag√≥n cristalino\n[COMPOSITION]: Plano medio\n..."
)

video = step2_animate_image(
    image,
    "El drag√≥n vuela lentamente, cristales reflejando luz"
)

# final = step3_upscale_video(video)
```

### 5.2 Prompt Injection y Variaciones Autom√°ticas

```python
def generate_prompt_variations(base_prompt, style_list):
    """Generar autom√°ticamente variaciones de prompt"""
    client = genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))
    
    variations = []
    
    for style in style_list:
        # Usar Gemini para enriquecer prompts
        enriched = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[{
                "parts": [{
                    "text": f"""Enriquece este prompt manteniendo esencia pero en estilo {style}:
"{base_prompt}"

Responde con SOLO el prompt mejorado, sin explicaciones."""
                }]
            }]
        )
        
        variations.append({
            "style": style,
            "prompt": enriched.text
        })
    
    return variations

# Uso:
base = "Una mujer en un caf√©"
styles = ["cyberpunk", "steampunk", "anime", "fotorrealista"]
variations = generate_prompt_variations(base, styles)

for v in variations:
    print(f"[{v['style']}] {v['prompt']}")
```

### 5.3 A/B Testing Autom√°tico

```python
def ab_test_prompts(prompt_a, prompt_b, num_iterations=3):
    """Comparar dos prompts y medir calidad"""
    client = genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))
    
    results = {"prompt_a": [], "prompt_b": []}
    
    for i in range(num_iterations):
        print(f"Iteraci√≥n {i+1}/{num_iterations}...")
        
        # Generar con ambos
        resp_a = client.models.generate_content(
            model="gemini-2.5-flash-image-preview",
            contents=[{"parts": [{"text": prompt_a}]}]
        )
        
        resp_b = client.models.generate_content(
            model="gemini-2.5-flash-image-preview",
            contents=[{"parts": [{"text": prompt_b}]}]
        )
        
        results["prompt_a"].append(resp_a)
        results["prompt_b"].append(resp_b)
        
        time.sleep(1)  # Evitar rate limits
    
    print(f"‚úì Test completado: {num_iterations} iteraciones cada uno")
    return results
```

### 5.4 Watermark Evasion (T√©cnicamente Legal)

Los watermarks invisibles (SynthID) son resistentes, pero puedes:

1. **Aplicar compresi√≥n estrat√©gica**:
```python
from PIL import Image
img = Image.open("generated.jpg")
img.save("output.jpg", quality=92)  # Compresi√≥n que reduce watermark invisible
```

2. **Re-fotografiar** (tomar foto de pantalla y procesarla)
3. **Usar modelos open-source locales** sin watermark (Fooocus, ComfyUI)

### 5.5 Integraci√≥n con GitHub Actions para CI/CD

```yaml
# .github/workflows/generate-images.yml
name: Auto Image Generation

on:
  schedule:
    - cron: "0 9 * * MON"  # Cada lunes a las 9 AM

jobs:
  generate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: pip install google-generativeai Pillow
      
      - name: Generate images
        env:
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        run: python batch_generator.py --config config.json --output ./images
      
      - name: Commit and push
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add images/
          git commit -m "Auto-generated images $(date +%Y-%m-%d)"
          git push
```

### 5.6 Streaming de Respuestas (Para Aplicaciones Web)

```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
import google.generativeai as genai

app = FastAPI()

@app.post("/stream-image")
async def stream_image(prompt: str):
    """Generar imagen y streamearla en tiempo real"""
    client = genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))
    
    async def image_generator():
        response = await client.models.generate_content(
            model="gemini-2.5-flash-image-preview",
            contents=[{"parts": [{"text": prompt}]}]
        )
        
        # Convertir a bytes y streamear
        image_data = response.candidates[0].content.parts[0].inline_data.data
        yield image_data
    
    return StreamingResponse(
        image_generator(),
        media_type="image/jpeg"
    )
```

---

## üìä Resumen Comparativo: Cu√°ndo Usar Cada Opci√≥n

| Caso de Uso | Mejor Opci√≥n | Por Qu√© |
|-------------|--------------|--------|
| **Prototipado r√°pido** | Pollinations.AI | API gratuita, sin config, instant |
| **Volumen alto (100+)** | Batch API | 50% descuento, as√≠ncrono |
| **Control total** | ComfyUI local | Sin l√≠mites, offline, privacidad |
| **Producci√≥n escalable** | Gemini Pro + Cache | Costo optimizado, confiable |
| **Video profesional** | Veo 3 + Gemini Ultra | Mejor calidad, audio nativo |
| **CI/CD automation** | Gemini CLI + GitHub Actions | Integraci√≥n perfecta |

---

## üîê Mejores Pr√°cticas de Seguridad

1. **Nunca commits API keys** ‚Üí Usar `dotenv` o secrets en GitHub
2. **Rate limiting** ‚Üí Implementar backoff exponencial
3. **Validaci√≥n de prompts** ‚Üí Sanitizar entrada de usuarios
4. **Logging** ‚Üí Registrar fallos para auditor√≠a
5. **Cost tracking** ‚Üí Monitorear uso de tokens

```python
# .env.example (commit esto sin keys)
GOOGLE_API_KEY=your_key_here
COMFYUI_SERVER=http://127.0.0.1:8188
BATCH_SIZE=5
RATE_LIMIT=10  # requests per minute
```

---

## üìö Recursos Adicionales

- **Docs oficial Gemini**: ai.google.dev/gemini-api
- **ComfyUI GitHub**: github.com/comfyanonymous/ComfyUI
- **Pollinations Repo**: github.com/pollinations/pollinations
- **r/StableDiffusion**: reddit.com/r/StableDiffusion (100k+ comunidad)
- **Gemini CLI Cookbook**: github.com/google-gemini/cookbook

---

**√öltima actualizaci√≥n**: Octubre 26, 2025
**Versi√≥n**: 1.0
**Mantenedor**: Comunidad de Investigaci√≥n de IA